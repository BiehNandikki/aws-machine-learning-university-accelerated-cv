{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLU Logo](../../data/MLU_Logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"0\">Machine Learning Accelerator - Computer Vision - Lecture 2</a>\n",
    "\n",
    "\n",
    "## Fine-Tuning with Pre-trained AlexNet \n",
    "\n",
    "In this notebook, we use a pre-trained [AlexNet](https://d2l.ai/chapter_convolutional-modern/alexnet.html) on the [MINC](http://opensurfaces.cs.cornell.edu/publications/minc/)  dataset. This notebook is similar to our previous notebook `MLA-CV-Lecture1-CNN.ipynb`, so we may skip some details to be concise. We will cover the following topics:\n",
    "\n",
    "1. <a href=\"#1\">Loading and Transforming Dataset</a>      \n",
    "2. <a href=\"#2\">Fine-tuning Pretrained AlexNet</a>\n",
    "3. <a href=\"#3\">Testing and Visualizations</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's update torch at least to v1.6.0 and d2l to v0.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\r\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install -q -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from d2l import torch as d2l\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a name=\"1\">Loading and Transforming Dataset</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "To load the dataset properly, we need to massage the image data a bit by some `transforms` functions. PyTorch provides a full list of [transforms functions](https://pytorch.org/docs/stable/torchvision/transforms.html) to enable a wide variety of data augmentation. \n",
    "\n",
    "We will process some simple data transformations in this example. First, we load the image data and resize it to the given size (224,224). Next, we convert the image tensor of shape (H x W x C) in the range [0, 255] to a float32 tensor of shape (C x H x W) in the range (0, 1) using the `ToTensor` class. Last, we normalize the tensor of shape (C x H x W) with its mean and standard deviation by `Normalize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0,0,0), std=(1,1,1))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0,0,0), std=(1,1,1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the predefined transform functions and load the train, validation and test sets.\n",
    "\n",
    "In practice, reading data can be a significant performance bottleneck, especially when our model is simple or when our computer is fast. To make our life easier when reading from the datasets, we use a `DataLoader` of Gluon, which reads a minibatch of data with size `batch_size` each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "path = '../../data/minc-2500'\n",
    "train_path = os.path.join(path, 'train')\n",
    "val_path = os.path.join(path, 'val')\n",
    "test_path = os.path.join(path, 'test')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path, transform=transform_train),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.ImageFolder(val_path, transform=transform_test),\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path, transform=transform_test),\n",
    "    batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a name=\"2\">Fine-tuning Pretrained AlexNet</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "To fine-tune a pretrained model, we need the following 4 steps:\n",
    "1. Define a neural network **finetune_net** with AlexNet architecture, and later reshape for given number of output classes. Note that for `torchvision.models.alexnet` the default parameter `pretrained` is False, which means it will only return us an AlexNet architecture rather than an AlexNet architecture with the pretrained weights.\n",
    "\n",
    "1. Initialize the **finetune_net** with [Xavier initialization](https://d2l.ai/chapter_multilayer-perceptrons/numerical-stability-and-init.html#xavier-initialization) to make sure our random initialized weights are neither too small nor too huge.\n",
    "\n",
    "1. Define another neural network, **pretrained_net**, and load the pretrained AlexNet model (which was trained on ImageNet) on it. Here, by specifying ``pretrained=True``, it will automatically download the model from torchvision model zoo if necessary. For more pretrained models, please refer to [torchvision Models](https://pytorch.org/docs/stable/torchvision/models.html).\n",
    "\n",
    "1. Transfer the trained weights (except last layer) from **pretrained_net** to **finetune_net**, and output **finetune_net**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extract = True\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def FineTuneAlexnet(classes, device):\n",
    "    '''\n",
    "    classes: number of the output classes \n",
    "    device: training context (CPU or GPU)\n",
    "    '''\n",
    "    finetune_net = torchvision.models.alexnet(pretrained=True).to(device)\n",
    "    set_parameter_requires_grad(finetune_net, feature_extract)\n",
    "    num_ftrs = finetune_net.classifier[6].in_features\n",
    "    finetune_net.classifier[6] = nn.Linear(num_ftrs, classes)\n",
    "    \n",
    "    return finetune_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a `net` using the `FineTuneAlexnet` on available GPUs (or CPUs) by defining the training context `ctx`. Since the MINC dataset has 6 categories, the output classes will be 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /home/ec2-user/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878e38eef7a149a4b5c1f8ca12bdc6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/233M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = d2l.try_gpu() # Create neural net on CPU or GPU depending on your training instances\n",
    "num_outputs = 6        # 6 output classes\n",
    "net = FineTuneAlexnet(num_outputs, device)\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up the hyperparameters for training, such as the learning rate of optimization algorithms. With the defined learning rate, we are able to create an `Optimizer` to infer the neural network \"how to optimize its weights\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "#  We will only update the parameters that we have just initialized,\n",
    "#  i.e. the parameters with requires_grad is True.\n",
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in net.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "optimizer = torch.optim.SGD(params_to_update, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides, we need to specify the loss function. Since this problem is a multiclass classification task, we will use softmax as our loss funciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network is almost ready to be finetuned! One last thing before the finetuning is to define the `accuracy` function for evulating our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_accuracy(output, label):\n",
    "    # output: (batch, num_output) float32 tensor\n",
    "    # label: (batch, ) int32 tensor\n",
    "    return (output.argmax(axis=1) == label.float()).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's the training time! Starting with the outer loop, we will have 10 epochs (10 full pass through our dataset). Within the inner loop, we yield each mini-batch from the `train_loader`, and update the weights based on the average statistics of this mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss 1.221, train acc 0.595, val loss 0.872, val acc 0.750\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net = net.to(device)\n",
    "    train_loss, val_loss, train_acc, valid_acc = 0., 0., 0., 0.\n",
    "    \n",
    "    # Training loop: (with autograd and trainer steps, etc.)\n",
    "    # This loop does the training of the neural network (weights are updated)\n",
    "    net.train()\n",
    "    for i, (data, label) in enumerate(train_loader):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        output = net(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        train_acc += finetune_accuracy(output, label)\n",
    "        train_loss += loss\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation loop:\n",
    "    # This loop tests the trained network on validation dataset\n",
    "    # No weight updates here\n",
    "    net.eval()\n",
    "    for i, (data, label) in enumerate(validation_loader):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        output = net(data)\n",
    "        valid_acc += finetune_accuracy(output, label)\n",
    "        val_loss += criterion(output, label)\n",
    "        \n",
    "    # Take averages\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "    val_loss /= len(validation_loader)\n",
    "    valid_acc /= len(validation_loader)\n",
    "    \n",
    "    print(\"Epoch %d: train loss %.3f, train acc %.3f, val loss %.3f, val acc %.3f\" % (\n",
    "        epoch+1, train_loss.detach().cpu().numpy(), train_acc.detach().cpu().numpy(),\n",
    "        val_loss.detach().cpu().numpy(), valid_acc.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to save the trained model, no matter using it for inference or to retrain it later. You can call `save_parameters` function to save the model architecture and its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a name=\"3\">Testing and Visualizations</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's validate our model predictions. Meanwhile, we use the `show_images` function and show the sample images and its prediction together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n",
    "    \"\"\"Plot a list of images.\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        ax.imshow(img.permute(1,2,0).numpy())\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_test_dataset = torchvision.datasets.ImageFolder(test_path,\n",
    "                                                       transform=transform_test)\n",
    "random_test_sample = torch.utils.data.DataLoader(random_test_dataset,\n",
    "                                                 batch_size=2*8, shuffle=True)\n",
    "\n",
    "net.eval()\n",
    "for data, label in random_test_sample:\n",
    "    show_images(data, 2, 8);\n",
    "    data = data.to(device)\n",
    "    pred = net(data)\n",
    "    print(pred.argmax(axis=1))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
